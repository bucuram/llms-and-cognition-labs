# LLMs & Cognition Labs

<img src="https://i.imgur.com/1AdS7wp.png" weight="200px">

[Intro to Pytorch](https://github.com/bucuram/llms-and-cognition-labs/blob/main/pytorch-tutorial.ipynb) 

Lab 0 - [Understanding LLMs + Labs Overview](https://github.com/bucuram/llms-and-cognition-labs/blob/main/lab0.ipynb) 

Lab 1 - [Working with Text](https://github.com/bucuram/llms-and-cognition-labs/blob/main/lab1.ipynb)

Lab 2 - [Attention Mechanisms](https://github.com/bucuram/llms-and-cognition-labs/blob/main/lab2.ipynb)

Lab 3 - [Implementing a GPT model from Scratch](https://github.com/bucuram/llms-and-cognition-labs/blob/main/lab3.ipynb)

Lab 4 - [Pretraining on Unlabeled Data](https://github.com/bucuram/llms-and-cognition-labs/blob/main/lab4.ipynb)

Lab 5 - [Finetuning for Text Classification](https://github.com/bucuram/llms-and-cognition-labs/blob/main/lab5.ipynb)

Lab 6 - [Finetuning To Follow Instructions](https://github.com/bucuram/llms-and-cognition-labs/blob/main/lab6.ipynb)

Useful resources:
- [The Annotated Transformer](https://github.com/harvardnlp/annotated-transformer/blob/master/AnnotatedTransformer.ipynb): line-by-line implementation of the [Attention Is All You Need](https://arxiv.org/pdf/1706.03762) paper.
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [Let's build GPT - Andrej Karpathy](https://www.youtube.com/watch?v=kCc8FmEb1nY)
- [Stanford CS25: V2 I Introduction to Transformers](https://www.youtube.com/watch?v=XfpMkf4rD6E&list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&index=12)

This lab is based on the https://github.com/rasbt/LLMs-from-scratch book/repo.
