{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca7fc8a0-280c-4979-b0c7-fc3a99b3b785",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5fc87",
   "metadata": {},
   "source": [
    "The current notebook covers:\n",
    "- An overview of the PyTorch deep learning library\n",
    "- Setting up an environment and workspace for deep learning\n",
    "- Tensors as a fundamental data structure for deep learning\n",
    "- The mechanics of training deep neural networks\n",
    "- Training models on GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf13d2-8fc2-483e-88cc-6b4310221e68",
   "metadata": {},
   "source": [
    "### 1. What is PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d4f91c",
   "metadata": {},
   "source": [
    "**PyTorch** (https://pytorch.org/) is an open-source Python-based deep learning\n",
    "library. \n",
    "\n",
    "According to Papers With Code (https://paperswithcode.com/trends),\n",
    "a platform that tracks and analyzes research papers, PyTorch has been the\n",
    "most widely used deep learning library for research since 2019 by a wide\n",
    "margin.\n",
    "\n",
    "Firstly, PyTorch is a tensor library that extends the concept of array-oriented\n",
    "programming library NumPy with the additional feature of accelerated\n",
    "computation on GPUs, thus providing a seamless switch between CPUs and\n",
    "GPUs.\n",
    "\n",
    "Secondly, PyTorch is an automatic differentiation engine, also known as\n",
    "autograd, which enables the automatic computation of gradients for tensor\n",
    "operations, simplifying backpropagation and model optimization.\n",
    "\n",
    "Finally, PyTorch is a deep learning library, meaning that it offers modular,\n",
    "flexible, and efficient building blocks (including pre-trained models, loss\n",
    "functions, and optimizers) for designing and training a wide range of deep\n",
    "learning models, catering to both researchers and developers.\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/1.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896e33ad",
   "metadata": {},
   "source": [
    "In this lab, we are going to use Pytorch 2.0.1.\n",
    "\n",
    "Instructions on how to install PyTorch locally on your machine can be found at: https://pytorch.org/get-started/previous-versions/#v201\n",
    "\n",
    "We will continue with the installation of PyTorch in the next cell.\n",
    "\n",
    "(it can take a few minutes to install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61067adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## only if you don't already have pytorch installed\n",
    "%pip install torch==2.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c6fb5",
   "metadata": {},
   "source": [
    "After installing Pytorch, we need to restart the kernel to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ee5660-5327-48e2-9104-a882b3b2afa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n"
     ]
    }
   ],
   "source": [
    "#importing pythorch and checking the version\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9183f14",
   "metadata": {},
   "source": [
    "If you are running the code on Google Colab, you can change the runtime and run the code on the GPU. To do this, go to the Runtime tab, click on Change runtime type, and select GPU from the Hardware accelerator dropdown.\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/5.webp\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d5004",
   "metadata": {},
   "source": [
    "Whether you are using Google Colab or your local machine, we can check if the GPU is available by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73ad4e4-7ec6-4467-a9e9-0cdf6d195264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e9ca4",
   "metadata": {},
   "source": [
    "If the command returns True, you are all set. If the command returns False,your computer may not have a compatible GPU, or PyTorch does not recognize it. However, you can still run the code on the CPU, as GPU is not required for the main part of this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2100cf2e-7459-4ab3-92a8-43e86ab35a9b",
   "metadata": {},
   "source": [
    "## 2. Understanding tensors\n",
    "\n",
    "Tensors represent a mathematical concept that generalizes vectors and\n",
    "matrices to potentially higher dimensions. In other words, tensors are\n",
    "mathematical objects that can be characterized by their order (or rank), which\n",
    "provides the number of dimensions. For example, a scalar (just a number) is a\n",
    "tensor of rank 0, a vector is a tensor of rank 1, and a matrix is a tensor of rank\n",
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c484e87-bfc9-4105-b0a7-1e23b2a72a30",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/6.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d7f785-e048-42bc-9182-a556af6bb7f4",
   "metadata": {},
   "source": [
    "### 2.1. Scalars, vectors, matrices, and tensors\n",
    "\n",
    "We can create objects of PyTorch's Tensor class using the torch.tensor\n",
    "function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a464d6-cec8-4363-87bd-ea4f900baced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# create a 0D tensor (scalar) from a Python integer\n",
    "tensor0d = torch.tensor(1)\n",
    "\n",
    "# create a 1D tensor (vector) from a Python list\n",
    "tensor1d = torch.tensor([1, 2, 3])\n",
    "\n",
    "# create a 2D tensor from a nested Python list\n",
    "tensor2d = torch.tensor([[1, 2], \n",
    "                         [3, 4]])\n",
    "\n",
    "# create a 3D tensor from a nested Python list\n",
    "tensor3d_1 = torch.tensor([[[1, 2], [3, 4]], \n",
    "                           [[5, 6], [7, 8]]])\n",
    "\n",
    "# create a 3D tensor from NumPy array\n",
    "ary3d = np.array([[[1, 2], [3, 4]], \n",
    "                  [[5, 6], [7, 8]]])\n",
    "tensor3d_2 = torch.tensor(ary3d)  # Copies NumPy array\n",
    "tensor3d_3 = torch.from_numpy(ary3d)  # Shares memory with NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe14c47-499a-4d48-b354-a0e6fd957872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "ary3d[0, 0, 0] = 999\n",
    "print(tensor3d_2) # remains unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e4c23a-cdba-46f5-a2dc-5fb32bf9117b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[999,   2],\n",
      "         [  3,   4]],\n",
      "\n",
      "        [[  5,   6],\n",
      "         [  7,   8]]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor3d_3) # changes because of memory sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dec48d-2b60-41a2-ac06-fef7e718605a",
   "metadata": {},
   "source": [
    "### 2.2. Tensor data types\n",
    "\n",
    "PyTorch adopts the default 64-bit integer data type from Python. We can\n",
    "access the data type of a tensor via the ``.dtype`` attribute of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f48c014-e1a2-4a53-b5c5-125812d4034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "tensor1d = torch.tensor([1, 2, 3])\n",
    "print(tensor1d.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96693a9",
   "metadata": {},
   "source": [
    "If we create tensors from Python floats, PyTorch creates tensors with a 32-bit\n",
    "precision by default, as we can see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5429a086-9de2-4ac7-9f14-d087a7507394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "floatvec = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(floatvec.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92855d",
   "metadata": {},
   "source": [
    "This choice is primarily due to the balance between precision and\n",
    "computational efficiency. A 32-bit floating point number offers sufficient\n",
    "precision for most deep learning tasks, while consuming less memory and\n",
    "computational resources than a 64-bit floating point number. Moreover, GPU\n",
    "architectures are optimized for 32-bit computations, and using this data type\n",
    "can significantly speed up model training and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7455117b",
   "metadata": {},
   "source": [
    "Moreover, it is possible to readily change the precision using a tensor's .to\n",
    "method. The following code demonstrates this by changing a 64-bit integer\n",
    "tensor into a 32-bit float tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a438d1-49bb-481c-8442-7cc2bb3dd4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "floatvec = tensor1d.to(torch.float32)\n",
    "print(floatvec.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2020deb5-aa02-4524-b311-c010f4ad27ff",
   "metadata": {},
   "source": [
    "### 2.3. Common PyTorch tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c02095f2-8a48-4953-b3c9-5313d4362ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d = torch.tensor([[1, 2, 3], \n",
    "                         [4, 5, 6]])\n",
    "tensor2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc7cf03",
   "metadata": {},
   "source": [
    "Using ``.shape`` attribute allows us to access the shape of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f33e1d45-5b2c-4afe-b4b2-66ac4099fd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ba85a1",
   "metadata": {},
   "source": [
    "As you can see above, ``.shape`` returns [2, 3], which means that the tensor\n",
    "has 2 rows and 3 columns. To reshape the tensor into a 3 by 2 tensor, we canuse the ``.reshape`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3a4129d-f870-4e03-9c32-cd8521cb83fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.reshape(3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5accd1f",
   "metadata": {},
   "source": [
    "However, note that the more common command for reshaping tensors in\n",
    "PyTorch is ``.view()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "589ac0a7-adc7-41f3-b721-155f580e9369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.view(3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9224123",
   "metadata": {},
   "source": [
    "Next, we can use ``.T`` to transpose a tensor, which means flipping it across its\n",
    "diagonal. Note that this is similar from reshaping a tensor as you can see\n",
    "based on the result below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344e307f-ba5d-4f9a-a791-2c75a3d1417e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55559f8",
   "metadata": {},
   "source": [
    "Lastly, the common way to multiply two matrices in PyTorch is the ``.matmul``\n",
    "method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19a75030-6a41-4ca8-9aae-c507ae79225c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d.matmul(tensor2d.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987607c3",
   "metadata": {},
   "source": [
    "However, we can also adopt the ``@`` operator, which accomplishes the same\n",
    "thing more compactly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c950bc-d640-4203-b210-3ac8932fe4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d @ tensor2d.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15bdeb-78e2-4870-8a4f-a9f591666f38",
   "metadata": {},
   "source": [
    "## 3. Seeing models as computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961e7919",
   "metadata": {},
   "source": [
    "PyTorch's automatic differentiation engine, autograd, provides functions to compute gradients in dynamic computational graphs automatically.\n",
    "\n",
    "A computational graph (or computation graph in short) is a directed graph\n",
    "that allows us to express and visualize mathematical expressions. In the\n",
    "context of deep learning, a computation graph lays out the sequence of\n",
    "calculations needed to compute the output of a neural network -- we will need\n",
    "this later to compute the required gradients for backpropagation, which is the\n",
    "main training algorithm for neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36004440",
   "metadata": {},
   "source": [
    "### 3.1. A logistic regression forward pass\n",
    "\n",
    "Let's look at a concrete example to illustrate the concept of a computation\n",
    "graph. The following code implements the forward pass (prediction step) of asimple logistic regression classifier, which can be seen as a single-layer\n",
    "neural network, returning a score between 0 and 1 that is compared to the true\n",
    "class label (0 or 1) when computing the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22af61e9-0443-4705-94d7-24c21add09c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0852)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "y = torch.tensor([1.0])  # true label\n",
    "x1 = torch.tensor([1.1]) # input feature\n",
    "w1 = torch.tensor([2.2]) # weight parameter\n",
    "b = torch.tensor([0.0])  # bias unit\n",
    "\n",
    "z = x1 * w1 + b          # net input\n",
    "a = torch.sigmoid(z)     # activation & output\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07f52a",
   "metadata": {},
   "source": [
    "The point of this example is to illustrate how we can think of a sequence of computations as a\n",
    "computation graph, as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e16c3-07df-44b6-9106-a42fb24452a9",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/7.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1422c",
   "metadata": {},
   "source": [
    "PyTorch builds a computation graph in the background, and we\n",
    "can use this to calculate gradients of a loss function with respect to the model\n",
    "parameters (here ``w1`` and ``b``) to train the model, which is the topic of the\n",
    "upcoming sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9424f26-2bac-47e7-b834-92ece802247c",
   "metadata": {},
   "source": [
    "## 4. Automatic differentiation made easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e22cfb",
   "metadata": {},
   "source": [
    "If we carry out computations in PyTorch, it will build such a graph internally by\n",
    "default if one of its terminal nodes has the ``requires_grad`` attribute set to\n",
    "``True``. This is useful if we want to compute gradients. Gradients are required\n",
    "when training neural networks via the popular backpropagation algorithm,\n",
    "which can be thought of as an implementation of the chain rule from calculus\n",
    "for neural networks, which is illustrated below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa2ee4-6f1d-448d-8707-67cd5278233c",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/8.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a77f7",
   "metadata": {},
   "source": [
    "### 4.1. Partial derivatives and gradients\n",
    "\n",
    "The above figure shows partial derivatives, which measure the rate at which a\n",
    "function changes with respect to one of its variables. A gradient is a vector\n",
    "containing all of the partial derivatives of a multivariate function, a function\n",
    "with more than one variable as input.\n",
    "\n",
    "If you are not familiar or don't remember the partial derivatives, gradients, or\n",
    "the chain rule from calculus, don't worry. On a high level, all you need to\n",
    "know is that the chain rule is a way to compute gradients of a\n",
    "loss function with respect to the model's parameters in a computation graph.\n",
    "This provides the information needed to update each parameter in a way that\n",
    "minimizes the loss function, which serves as a proxy for measuring the\n",
    "model's performance, using a method such as gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b405d1",
   "metadata": {},
   "source": [
    "### 4.2. Computing gradients via autograd\n",
    "\n",
    "By tracking every operation performed on tensors, PyTorch's autograd engine\n",
    "constructs a computational graph in the background. Then, calling the ``grad``\n",
    "function, we can compute the gradient of the loss with respect to model\n",
    "parameter w1 as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebf5cef7-48d6-4d2a-8ab0-0fb10bdd7d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.0898]),)\n",
      "(tensor([-0.0817]),)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "\n",
    "y = torch.tensor([1.0])\n",
    "x1 = torch.tensor([1.1])\n",
    "w1 = torch.tensor([2.2], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "z = x1 * w1 + b \n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)\n",
    "\n",
    "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
    "grad_L_b = grad(loss, b, retain_graph=True)\n",
    "\n",
    "print(grad_L_w1)\n",
    "print(grad_L_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da63452",
   "metadata": {},
   "source": [
    "Above, we have been using the grad function \"manually,\" which can be\n",
    "useful for experimentation, debugging, and demonstrating concepts. But in\n",
    "practice, PyTorch provides even more high-level tools to automate this\n",
    "process. For instance, we can call ``.backward`` on the loss, and PyTorch will\n",
    "compute the gradients of all the leaf nodes in the graph, which will be stored\n",
    "via the tensors' ``.grad`` attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93c5875d-f6b2-492c-b5ef-7e132f93a4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0898])\n",
      "tensor([-0.0817])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "\n",
    "print(w1.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53bdd7d-44e6-40ab-8a5a-4eef74ef35dc",
   "metadata": {},
   "source": [
    "## 5. Implementing multilayer neural networks\n",
    "\n",
    "This section focuses on PyTorch as a library for implementing\n",
    "deep neural networks. We focus on a multilayer perceptron, which is\n",
    "a fully connected neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cb9787-2bc8-4379-9e8c-a3401ac63c51",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/9.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cb3a28",
   "metadata": {},
   "source": [
    "When implementing a neural network in PyTorch, we typically subclass the\n",
    "``torch.nn.Module`` class to define our own custom network architecture. This\n",
    "Module base class provides a lot of functionality, making it easier to build and\n",
    "train models. For instance, it allows us to encapsulate layers and operations\n",
    "and keep track of the model's parameters.\n",
    "\n",
    "\n",
    "Within this subclass, we define the network layers in the ``__init__``\n",
    "constructor and specify how they interact in the forward method. The ``forward``\n",
    "method describes how the input data passes through the network and comes\n",
    "together as a computation graph.\n",
    "\n",
    "In contrast, the ``backward`` method (shown before), which we typically do not need to\n",
    "implement ourselves, is used during training to compute gradients of the loss\n",
    "function with respect to the model parameters.\n",
    "\n",
    "### 5.1. A multilayer perceptron with two hidden layers\n",
    "\n",
    "The following code implements a classic multilayer perceptron with two\n",
    "hidden layers to illustrate a typical usage of the Module class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84b749e1-7768-4cfe-94d6-a08c7feff4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "                \n",
    "            # 1st hidden layer\n",
    "            torch.nn.Linear(num_inputs, 30),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(30, 20),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # output layer\n",
    "            torch.nn.Linear(20, num_outputs),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb79c55",
   "metadata": {},
   "source": [
    "We can then instantiate a new neural network object as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5b59e2e-1930-456d-93b9-f69263e3adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(50, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233e994",
   "metadata": {},
   "source": [
    "But before using this new model object, it is often useful to call ``print`` on the\n",
    "model to see a summary of its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39d02a21-33e7-4879-8fd2-d6309faf2f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a33f956",
   "metadata": {},
   "source": [
    "Note that we used the ``Sequential`` class when we implemented the ``NeuralNetwork`` class. Using ``Sequential`` is not required, but it can make our\n",
    "life easier if we have a series of layers that we want to execute in a specific\n",
    "order, as is the case here. This way, after instantiating ``self.layers =\n",
    "Sequential(...)`` in the ``__init__`` constructor, we just have to call the\n",
    "``self.layers`` instead of calling each layer individually in the\n",
    "``NeuralNetwork``'s forward method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b55f6c",
   "metadata": {},
   "source": [
    "Let's check the total number of trainable parameters of this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94535738-de02-4c2a-9b44-1cd186fa990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable model parameters: 2213\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of trainable model parameters:\", num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b762913",
   "metadata": {},
   "source": [
    "Note that each parameter for which ``requires_grad=True`` counts as a\n",
    "trainable parameter and will be updated during training.\n",
    "\n",
    "In the case of our neural network model with the two hidden layers above,\n",
    "these trainable parameters are contained in the ``torch.nn.Linear`` layers. A\n",
    "linear layer multiplies the inputs with a weight matrix and adds a bias vector.\n",
    "This is sometimes also referred to as a feedforward or fully connected layer.\n",
    "\n",
    "Based on the ``print(model)`` call we executed above, we can see that the first\n",
    "``Linear layer`` is at index position 0 in the layers attribute. We can access the\n",
    "corresponding weight parameter matrix as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c394106-ad71-4ccb-a3c9-9b60af3fa748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1182,  0.0606, -0.1292,  ..., -0.1126,  0.0735, -0.0597],\n",
      "        [-0.0249,  0.0154, -0.0476,  ..., -0.1001, -0.1288,  0.1295],\n",
      "        [ 0.0641,  0.0018, -0.0367,  ..., -0.0990, -0.0424, -0.0043],\n",
      "        ...,\n",
      "        [ 0.0618,  0.0867,  0.1361,  ..., -0.0254,  0.0399,  0.1006],\n",
      "        [ 0.0842, -0.0512, -0.0960,  ..., -0.1091,  0.1242, -0.0428],\n",
      "        [ 0.0518, -0.1390, -0.0923,  ..., -0.0954, -0.0668, -0.0037]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab069ba",
   "metadata": {},
   "source": [
    "Since this is a large matrix that is not shown in its entirety, let's use the\n",
    "``.shape`` attribute to show its dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1da9a35e-44f3-460c-90fe-304519736fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 50])\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c043dc8",
   "metadata": {},
   "source": [
    "The weight matrix above is a 30x50 matrix, and we can see that the\n",
    "``requires_grad`` is set to True, which means its entries are trainable -- this is\n",
    "the default setting for weights and biases in ``torch.nn.Linear``.\n",
    "\n",
    "Note that if you execute the code above on your computer, the numbers in the\n",
    "weight matrix will likely differ from those shown above. This is because the\n",
    "model weights are initialized with small random numbers, which are different\n",
    "each time we instantiate the network. In deep learning, initializing model\n",
    "weights with small random numbers is desired to break symmetry during\n",
    "training -- otherwise, the nodes would be just performing the same operations\n",
    "and updates during backpropagation, which would not allow the network to\n",
    "learn complex mappings from inputs to outputs.\n",
    "\n",
    "However, while we want to keep using small random numbers as initial\n",
    "values for our layer weights, we can make the random number initialization\n",
    "reproducible by seeding PyTorch's random number generator via\n",
    "``manual_seed``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b201882b-9285-4db9-bb63-43afe6a2ff9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
      "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
      "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
      "        ...,\n",
      "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
      "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
      "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = NeuralNetwork(50, 3)\n",
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c3103f",
   "metadata": {},
   "source": [
    "Let's see how we use the ``NeuralNetwork`` the ``forward`` pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57eadbae-90fe-43a3-a33f-c23a095ba42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "X = torch.rand((1, 50))\n",
    "out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab032956",
   "metadata": {},
   "source": [
    "In the code above, we generated a single random training example X as a toy\n",
    "input (note that our network expects 50-dimensional feature vectors) and fed\n",
    "it to the model, returning three scores. When we call ``model(x)``, it will\n",
    "automatically execute the forward pass of the model.\n",
    "\n",
    "The forward pass refers to calculating output tensors from input tensors. This\n",
    "involves passing the input data through all the neural network layers, starting\n",
    "from the input layer, through hidden layers, and finally to the output layer.\n",
    "\n",
    "These three numbers returned above correspond to a score assigned to each\n",
    "of the three output nodes. Notice that the output tensor also includes a\n",
    "``grad_fn`` value.\n",
    "\n",
    "``grad_fn=<AddmmBackward0>`` represents the last-used function to\n",
    "compute a variable in the computational graph. It specifies the\n",
    "operation that was performed. In this case, it is an Addmm operation. Addmm\n",
    "stands for matrix multiplication (mm) followed by an addition (Add)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d20ba",
   "metadata": {},
   "source": [
    "When we use a model for inference (for instance, making predictions) rather than\n",
    "training, it is a best practice to use the ``torch.no_grad()`` context manager, as\n",
    "shown below. This tells PyTorch that it doesn't need to keep track of the\n",
    "gradients, which can result in significant savings in memory and\n",
    "computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48d720cb-ef73-4b7b-92e0-8198a072defd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1262,  0.1080, -0.1792]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7272f8",
   "metadata": {},
   "source": [
    "In PyTorch, it's common practice to code models such that they return the\n",
    "outputs of the last layer (logits) without passing them to a nonlinear\n",
    "activation function. That's because PyTorch's commonly used loss functions\n",
    "combine the ``softmax`` (or ``sigmoid`` for binary classification) operation with the\n",
    "negative log-likelihood loss in a single class. The reason for this is numerical\n",
    "efficiency and stability. So, if we want to compute class-membership\n",
    "probabilities for our predictions, we have to call the ``softmax`` function\n",
    "explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10df3640-83c3-4061-a74d-08f07a5cc6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3113, 0.3934, 0.2952]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = torch.softmax(model(X), dim=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb4a8a",
   "metadata": {},
   "source": [
    "The values can now be interpreted as class-membership probabilities that\n",
    "sum up to 1. The values are roughly equal for this random input, which is\n",
    "expected for a randomly initialized model without training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19858180-0f26-43a8-b2c3-7ed40abf9f85",
   "metadata": {},
   "source": [
    "## 6. Setting up efficient data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38549b85",
   "metadata": {},
   "source": [
    "We have defined a custom neural network model above. Before\n",
    "we can train this model, we have to briefly talk about creating efficient data\n",
    "loaders in PyTorch, which we will iterate over when training the model.\n",
    "\n",
    "We will implement a\n",
    "custom ``Dataset`` class that we will use to create a training and a test dataset\n",
    "that we'll then use to create the data loaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98d8fc-5618-47a2-bc72-153818972a24",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/10.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f922c",
   "metadata": {},
   "source": [
    "### 6.1. Creating a small toy dataset\n",
    "\n",
    "Let's start by creating a simple toy dataset of five training examples with two\n",
    "features each. Accompanying the training examples, we also create a tensor\n",
    "containing the corresponding class labels: three examples below to class 0,\n",
    "and two examples belong to class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a9940",
   "metadata": {},
   "source": [
    "##### Class label numbering\n",
    "\n",
    "PyTorch requires that class labels start with label 0, and the largest class label\n",
    "value should not exceed the number of output nodes minus 1 (since Python\n",
    "index counting starts at 0). So, if we have class labels 0, 1, 2, 3, and 4, the\n",
    "neural network output layer should consist of 5 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9dc2745-8be8-4344-80ef-325f02cda7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor([\n",
    "    [-1.2, 3.1],\n",
    "    [-0.9, 2.9],\n",
    "    [-0.5, 2.6],\n",
    "    [2.3, -1.1],\n",
    "    [2.7, -1.5]\n",
    "])\n",
    "\n",
    "y_train = torch.tensor([0, 0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09552d68",
   "metadata": {},
   "source": [
    "In addition, we also make a test set\n",
    "consisting of two entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88283948-5fca-461a-98a1-788b6be191d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor([\n",
    "    [-0.8, 2.8],\n",
    "    [2.6, -1.6],\n",
    "])\n",
    "\n",
    "y_test = torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbbab9e",
   "metadata": {},
   "source": [
    "### 6.2. Defining a custom Dataset class\n",
    "\n",
    "We create a custom dataset class, ``ToyDataset``, by subclassing from\n",
    "PyTorch's ``Dataset`` parent class.\n",
    "\n",
    "In PyTorch, the three main components of a custom Dataset class are the\n",
    "``__init__`` constructor, the ``__getitem__`` method, and the ``__len__`` method.\n",
    "\n",
    "In the ``__init__`` method, we set up attributes that we can access later in the\n",
    "``__getitem__`` and ``__len__`` methods. This could be file paths, file objects,\n",
    "database connectors, and so on. Since we created a tensor dataset that sits in\n",
    "memory, we are simply assigning X and y to these attributes, which are\n",
    "placeholders for our tensor objects.\n",
    "\n",
    "In the ``__getitem__`` method, we define instructions for returning exactly one\n",
    "item from the dataset via an index. This means the features and the class\n",
    "label corresponding to a single training example or test instance.\n",
    "\n",
    "Finally, the ``__len__`` method constrains instructions for retrieving the length\n",
    "of the dataset. Here, we use the ``.shape`` attribute of a tensor to return the\n",
    "number of rows in the feature array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edf323e2-1789-41a0-8e44-f3cab16e5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.features = X\n",
    "        self.labels = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        one_x = self.features[index]\n",
    "        one_y = self.labels[index]        \n",
    "        return one_x, one_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "train_ds = ToyDataset(X_train, y_train)\n",
    "test_ds = ToyDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe30e2c",
   "metadata": {},
   "source": [
    "In the case of the training dataset, we\n",
    "have five rows, which we can double-check as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7014705-1fdc-4f72-b892-d8db8bebc331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf342be",
   "metadata": {},
   "source": [
    "### 6.3. Instantiating data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53219fe",
   "metadata": {},
   "source": [
    "This custom ``ToyDataset`` class's purpose is to use it to instantiate a PyTorch\n",
    "``DataLoader``. The ``DataLoader`` class is used to sample from the ``ToyDataset``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ec6627a-4c3f-481a-b794-d2131be95eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c9446de-5e4b-44fa-bf9a-a63e2661027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ToyDataset(X_test, y_test)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad2f216",
   "metadata": {},
   "source": [
    "After instantiating the training data loader, we can iterate over it as shown\n",
    "below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99d4404c-9884-419f-979c-f659742d86ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Batch 2: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863ac52",
   "metadata": {},
   "source": [
    "As we can see based on the output above, the ``train_loader`` iterates over the\n",
    "training dataset visiting each training example exactly once. This is known as\n",
    "a training epoch. Since we seeded the random number generator using\n",
    "``torch.manual_seed(123)`` above, you should get the exact same shuffling\n",
    "order of training examples as shown above. However if you iterate over the\n",
    "dataset a second time, you will see that the shuffling order will change. This\n",
    "is desired to prevent deep neural networks getting caught in repetitive update\n",
    "cycles during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be2909",
   "metadata": {},
   "source": [
    "Note that we specified a batch size of 2 above, but the 3rd batch only\n",
    "contains a single example. That's because we have five training examples,\n",
    "which is not evenly divisible by 2. In practice, having a substantially smaller\n",
    "batch as the last batch in a training epoch can disturb the convergence during\n",
    "training. To prevent this, it's recommended to set ``drop_last=True``, which\n",
    "will drop the last batch in each epoch, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d003f7e-7a80-40bf-a7fb-7a0d7dbba9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bf63d5",
   "metadata": {},
   "source": [
    "Now, iterating over the training loader, we can see that the last batch is\n",
    "omitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4db4d7f4-82da-44a4-b94e-ee04665d9c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 2: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bef9687",
   "metadata": {},
   "source": [
    "### 6.4. Data loading with/ without multiple workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f1d43",
   "metadata": {},
   "source": [
    "The ``num_workers=0`` in the ``DataLoader`` is crucial for parallelizing data\n",
    "loading and preprocessing. When ``num_workers`` is set to 0, the data loading\n",
    "will be done in the main process and not in separate worker processes. This\n",
    "might seem unproblematic, but it can lead to significant slowdowns during\n",
    "model training when we train larger networks on a GPU. This is because\n",
    "instead of focusing solely on the processing of the deep learning model, the\n",
    "CPU must also take time to load and preprocess the data. As a result, the\n",
    "GPU can sit idle while waiting for the CPU to finish these tasks. In contrast,\n",
    "when ``num_workers`` is set to a number greater than zero, multiple worker\n",
    "processes are launched to load data in parallel, freeing the main process to\n",
    "focus on training your model and better utilizing your system's resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03ed57-df38-4ee0-a553-0863450df39b",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-a_compressed/11.webp\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904ca82-e50f-4f3d-a3ac-fc6ca53dd00e",
   "metadata": {},
   "source": [
    "## 7. A typical training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e87e8",
   "metadata": {},
   "source": [
    "We've discussed all the requirements for training neural networks: PyTorch's tensor library, autograd, the Module API, and efficient data loaders.\n",
    "Let's now combine all these things and train a neural network on the toy\n",
    "dataset from the previous section.\n",
    "\n",
    "### 7.1. Neural network training in PyTorch\n",
    "\n",
    "We will initialize a model with two inputs and two outputs. That's\n",
    "because the toy dataset from the previous section has two input features and\n",
    "two class labels to predict. We used a stochastic gradient descent (SGD)\n",
    "optimizer with a ``learning rate`` (lr) of 0.5. The ``learning rate`` is a\n",
    "hyperparameter, meaning it's a tunable setting that we have to experiment\n",
    "with based on observing the loss. Ideally, we want to choose a learning rate\n",
    "such that the loss converges after a certain number of epochs -- the number of\n",
    "``epochs`` is another hyperparameter to choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88765661",
   "metadata": {},
   "source": [
    "It is important to include an ``optimizer.zero_grad()`` call in each update\n",
    "round to reset the gradients to zero. Otherwise, the gradients will accumulate,\n",
    "which may be undesired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93f1791a-d887-4fc5-a307-5e5bde9e06f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003 | Batch 000/002 | Train/Val Loss: 0.75\n",
      "Epoch: 001/003 | Batch 001/002 | Train/Val Loss: 0.65\n",
      "Epoch: 002/003 | Batch 000/002 | Train/Val Loss: 0.44\n",
      "Epoch: 002/003 | Batch 001/002 | Train/Val Loss: 0.13\n",
      "Epoch: 003/003 | Batch 000/002 | Train/Val Loss: 0.03\n",
      "Epoch: 003/003 | Batch 001/002 | Train/Val Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "\n",
    "        logits = model(features)\n",
    "        \n",
    "        loss = F.cross_entropy(logits, labels) # Loss function\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        ### LOGGING\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
    "              f\" | Train/Val Loss: {loss:.2f}\")\n",
    "\n",
    "    model.eval()\n",
    "    # Optional model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cad1244",
   "metadata": {},
   "source": [
    "The loss reaches zero after 3 epochs, a sign that the model\n",
    "converged on the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3217b888",
   "metadata": {},
   "source": [
    "After we trained the model, we can use it to make predictions, as shown\n",
    "below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00dcf57f-6a7e-4af7-aa5a-df2cb0866fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8569, -4.1618],\n",
      "        [ 2.5382, -3.7548],\n",
      "        [ 2.0944, -3.1820],\n",
      "        [-1.4814,  1.4816],\n",
      "        [-1.7176,  1.7342]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_train)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b2e909",
   "metadata": {},
   "source": [
    "In the above cell, we can see the logits for the train samples.\n",
    "\n",
    "To obtain the class membership probabilities, we can then use PyTorch's\n",
    "softmax function. \n",
    "\n",
    "Let's consider the first row in the code output below. Here, the first value\n",
    "(column) means that the training example has a 99.91% probability of\n",
    "belonging to class 0 and a 0.09% probability of belonging to class 1. \n",
    "\n",
    "(The\n",
    "``set_printoptions`` call is used here to make the outputs more legible.)\n",
    "\n",
    "We can convert the probabilities into class labels predictions using PyTorch's\n",
    "``argmax`` function, which returns the index position of the highest value in each\n",
    "row if we set ``dim=1`` (setting ``dim=0`` would return the highest value in each\n",
    "column, instead):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19be7390-18b8-43f9-9841-d7fb1919f6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.9991,     0.0009],\n",
      "        [    0.9982,     0.0018],\n",
      "        [    0.9949,     0.0051],\n",
      "        [    0.0491,     0.9509],\n",
      "        [    0.0307,     0.9693]])\n",
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "probas = torch.softmax(outputs, dim=1)\n",
    "print(probas)\n",
    "\n",
    "predictions = torch.argmax(probas, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1773e87",
   "metadata": {},
   "source": [
    "Note that it is unnecessary to compute ``softmax`` probabilities to obtain the\n",
    "class labels. We could also apply the ``argmax`` function to the logits (outputs)\n",
    "directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07e7e530-f8d3-429c-9f5e-cf8078078c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.argmax(outputs, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff2ff1",
   "metadata": {},
   "source": [
    "Above, we computed the predicted labels for the training dataset. Since the\n",
    "training dataset is relatively small, we could compare it to the true training\n",
    "labels by eye and see that the model is 100% correct. We can double-check\n",
    "this using the ``==`` comparison operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f756f0d-63c8-41b5-a5d8-01baa847e026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions == y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa7793",
   "metadata": {},
   "source": [
    "Using ``torch.sum``, we can count the number of correct prediction as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da274bb0-f11c-4c81-a880-7a031fbf2943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(predictions == y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf85e2b",
   "metadata": {},
   "source": [
    "Since the dataset consists of 5 training examples, we have 5 out of 5\n",
    "predictions that are correct, which equals 5/5  100% = 100% prediction\n",
    "accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cbd3c6",
   "metadata": {},
   "source": [
    "### 7.2. A function to compute the prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23f57f",
   "metadata": {},
   "source": [
    "To generalize the computation of the prediction accuracy, let's\n",
    "implement a ``compute_accuracy`` function.\n",
    "\n",
    "The function iterates over a data loader to compute the\n",
    "number and fraction of the correct predictions. This is because when we work\n",
    "with large datasets, we typically can only call the model on a small part of the\n",
    "dataset due to memory limitations. The ``compute_accuracy`` function above is\n",
    "a general method that scales to datasets of arbitrary size since, in each\n",
    "iteration, the dataset chunk that the model receives is the same size as the\n",
    "batch size seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16d62314-8dee-45b0-8f55-9e5aae2b24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "\n",
    "    model = model.eval()\n",
    "    correct = 0.0\n",
    "    total_examples = 0\n",
    "    \n",
    "    for idx, (features, labels) in enumerate(dataloader):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(features)\n",
    "        \n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        compare = labels == predictions\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return (correct / total_examples).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a64703",
   "metadata": {},
   "source": [
    "We can then apply the function to the training as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f6c9c17-2a5f-46c0-804b-873f169b729a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8e6a1",
   "metadata": {},
   "source": [
    "Similarly, we can apply the function to the test set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "311ed864-e21e-4aac-97c7-c6086caef27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5cd469-3a45-4394-944b-3ce543f41dac",
   "metadata": {},
   "source": [
    "## 8. Saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcce29f",
   "metadata": {},
   "source": [
    "Here's the recommended way how we can save models in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b013127d-a2c3-4b04-9fb3-a6a7c88d83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a654e",
   "metadata": {},
   "source": [
    "The model's ``state_dict`` is a Python dictionary object that maps each layer in\n",
    "the model to its trainable parameters (weights and biases). Note that\n",
    "``\"model.pth\"`` is an arbitrary filename for the model file saved to disk. We can\n",
    "give it any name and file ending we like; however, ``.pth`` and ``.pt`` are the most\n",
    "common conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309bd7a9",
   "metadata": {},
   "source": [
    "Once we saved the model, we can restore it from disk as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2b428c2-3a44-4d91-97c4-8298cf2b51eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(2, 2) # needs to match the original model exactly\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454cbbea",
   "metadata": {},
   "source": [
    "The ``torch.load(\"model.pth\")`` function reads the file ``\"model.pth\"`` and\n",
    "reconstructs the Python dictionary object containing the model's parameters\n",
    "while ``model.load_state_dict()`` applies these parameters to the model,\n",
    "effectively restoring its learned state from when we saved it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f891c013-43da-4a05-973d-997be313d2d8",
   "metadata": {},
   "source": [
    "## 9. Optimizing training performance with GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd3162",
   "metadata": {},
   "source": [
    "In this section, we will see how we can utilize GPUs,\n",
    "which will accelerate deep neural network training compared to regular\n",
    "CPUs. First, we will introduce the main concepts behind GPU computing in\n",
    "PyTorch. Then, we will train a model on a single GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ae888-cabf-49c9-bad6-ecdce774db57",
   "metadata": {},
   "source": [
    "### 9.1. PyTorch computations on GPU devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419f2092",
   "metadata": {},
   "source": [
    "In this part of the lab, we will learn how to move tensors and models to GPU devices and how to perform computations on GPUs. For this, we will need to check again if the GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b5445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b58503",
   "metadata": {},
   "source": [
    "Now, suppose we have two tensors that we can add as follows -- this\n",
    "computation will be carried out on the CPU by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991cc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "tensor_1 = torch.tensor([1., 2., 3.])\n",
    "tensor_2 = torch.tensor([4., 5., 6.])\n",
    "\n",
    "print(tensor_1 + tensor_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01699b11",
   "metadata": {},
   "source": [
    "We can now use the ``.to()`` method to transfer these tensors onto a GPU\n",
    "and perform the addition there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024817cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tensor_1 = tensor_1.to(\"cuda\")\n",
    "tensor_2 = tensor_2.to(\"cuda\")\n",
    "\n",
    "print(tensor_1 + tensor_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf953a",
   "metadata": {},
   "source": [
    "Notice that the resulting tensor now includes the device information,\n",
    "``device='cuda:0'``, which means that the tensors reside on the first GPU. If\n",
    "your machine hosts multiple GPUs, you have the option to specify which\n",
    "GPU you'd like to transfer the tensors to. You can do this by indicating the\n",
    "device ID in the transfer command. For instance, you can use\n",
    "``.to(\"cuda:0\")``, ``.to(\"cuda:1\")``, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e8d146",
   "metadata": {},
   "source": [
    "However, it is important to note that all tensors must be on the same device.\n",
    "Otherwise, the computation will fail, as shown below, where one tensor\n",
    "resides on the CPU and the other on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e334c19",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "\u001b[0;32m/tmp/ipykernel_2321/2079609735.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0mtensor_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtensor_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "tensor_1 = tensor_1.to(\"cpu\")\n",
    "print(tensor_1 + tensor_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99811829-b817-42ea-b03e-d35374debcc0",
   "metadata": {},
   "source": [
    "### 9.2. A training loop on a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14528434",
   "metadata": {},
   "source": [
    "We are using the same ToyDataset, DataLoader, and NeuralNetwork as before, but we will train the model on a GPU this time.\n",
    "\n",
    "We can modify the training loop from section 7  to run on a GPU.\n",
    "This requires only changing three lines of code, as shown\n",
    "below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d357775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/003 | Batch 000/002 | Train/Val Loss: 0.75\n",
      "Epoch: 001/003 | Batch 001/002 | Train/Val Loss: 0.65\n",
      "Epoch: 002/003 | Batch 000/002 | Train/Val Loss: 0.44\n",
      "Epoch: 002/003 | Batch 001/002 | Train/Val Loss: 0.13\n",
      "Epoch: 003/003 | Batch 000/002 | Train/Val Loss: 0.03\n",
      "Epoch: 003/003 | Batch 001/002 | Train/Val Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # NEW\n",
    "model = model.to(device) # NEW\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "\n",
    "        features, labels = features.to(device), labels.to(device) # NEW\n",
    "        logits = model(features)\n",
    "        loss = F.cross_entropy(logits, labels) # Loss function\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ### LOGGING\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
    "              f\" | Train/Val Loss: {loss:.2f}\")\n",
    "\n",
    "    model.eval()\n",
    "    # Optional model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692894db",
   "metadata": {},
   "source": [
    "We can also use ``model.to(\"cuda\")`` directly instead of ``device = torch.device(\"cuda\")`` and ``model = model.to(device)``.\n",
    "\n",
    "We also added the line ``device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")`` to make the code executable on a\n",
    "CPU if a GPU is not available, which is usually considered best practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a6461",
   "metadata": {},
   "source": [
    "In the case of the modified training loop above, we probably won't see a\n",
    "speed-up because of the memory transfer cost from CPU to GPU. However,\n",
    "we can expect a significant speed-up when training deep neural networks,\n",
    "especially large language models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
